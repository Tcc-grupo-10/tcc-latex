	%% abtex2-modelo-trabalho-academico.tex, v-1.9.6 laurocesar
%% Copyright 2012-2016 by abnTeX2 group at http://www.abntex.net.br/ 
%%
%% This work may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either version 1.3
%% of this license or (at your option) any later version.
%% The latest version of this license is in
%%   http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 2005/12/01 or later.
%%
%% This work has the LPPL maintenance status `maintained'.
%% 
%% The Current Maintainer of this work is the abnTeX2 team, led
%% by Lauro César Araujo. Further information are available on 
%% http://www.abntex.net.br/
%%
%% This work consists of the files abntex2-modelo-trabalho-academico.tex,
%% abntex2-modelo-include-comandos and abntex2-modelo-references.bib
%%

% ------------------------------------------------------------------------
% ------------------------------------------------------------------------
% abnTeX2: Modelo de Trabalho Academico (tese de doutorado, dissertacao de
% mestrado e trabalhos monograficos em geral) em conformidade com 
% ABNT NBR 14724:2011: Informacao e documentacao - Trabalhos academicos -
% Apresentacao
% ------------------------------------------------------------------------
% ------------------------------------------------------------------------

\documentclass[
	% -- opções da classe memoir --
	12pt,				% tamanho da fonte
	openright,			% capítulos começam em pág ímpar (insere página vazia caso preciso)
	oneside,			% para impressão em recto e verso. Oposto a oneside
	a4paper,			% tamanho do papel. 
	% -- opções da classe abntex2 --
	%chapter=TITLE,		% títulos de capítulos convertidos em letras maiúsculas
	%section=TITLE,		% títulos de seções convertidos em letras maiúsculas
	%subsection=TITLE,	% títulos de subseções convertidos em letras maiúsculas
	%subsubsection=TITLE,% títulos de subsubseções convertidos em letras maiúsculas
	% -- opções do pacote babel --
	english,			% idioma adicional para hifenização
	spanish,			% idioma adicional para hifenização
	brazil				% o último idioma é o principal do documento
	]{abntex2}

% ---
% Pacotes básicos 
% ---
\usepackage{lmodern}			% Usa a fonte Latin Modern	
\usepackage[T1]{fontenc}       % Selecao de codigos de fonte.		
\usepackage[utf8]{inputenc}		% Codificacao do documento (conversão automática dos acentos)
\usepackage{lastpage}			% Usado pela Ficha catalográfica
\usepackage{indentfirst}		% Indenta o primeiro parágrafo de cada seção.
\usepackage{color}				% Controle das cores
\usepackage{graphicx}			% Inclusão de gráficos
\usepackage{microtype} 			% para melhorias de justificação
\usepackage{mathtools}

% ---

% ---
% Pacotes de citações
% ---
\usepackage[brazilian,hyperpageref]{backref}	 % Paginas com as citações na bibl
\usepackage[alf]{abntex2cite}	% Citações padrão ABNT

% --- 
% CONFIGURAÇÕES DE PACOTES
% --- 

% ---
% Configurações do pacote backref
% Usado sem a opção hyperpageref de backref
\renewcommand{\backrefpagesname}{Citado na(s) página(s):~}
% Texto padrão antes do número das páginas
\renewcommand{\backref}{}
% Define os textos da citação
\renewcommand*{\backrefalt}[4]{
	\ifcase #1 %
		%Nenhuma citação no texto.%
	\or
		%Citado na página #2.%
	\else
		%Citado #1 vezes nas páginas #2.%
	\fi}%
	
	
\graphicspath{ {images/} }

% ---


% ---
% Informações de dados para CAPA e FOLHA DE ROSTO
% ---
\titulo{Algoritmo de Processamento de Linguagem Natural para Análise de Sentimento em Mídias Sociais}
\data{2017}
\autor{Flavia Pezoti \and Aline Murakami \and Eric Campanatti \and Gabriel Alves }
\instituicao{Pontifícia Universidade Católica de São Paulo}
\local{São Paulo}
\orientador{Fernando Antonio de Castro Giorno}
\coorientador{Carlos Eduardo de Barros Paes}
\tipotrabalho{}
% O preambulo deve conter o tipo do trabalho, o objetivo, 
% o nome da instituição e a área de concentração 
\preambulo{}
% ---



% ---
% Configurações de aparência do PDF final

% informações do PDF
\makeatletter
\hypersetup{
     	%pagebackref=true,
		pdftitle={\@title}, 
		pdfauthor={\@author},
    	pdfsubject={\imprimirpreambulo},
	    pdfcreator={LaTeX with abnTeX2},
		pdfkeywords={abnt}{latex}{abntex}{abntex2}{trabalho acadêmico}, 
		colorlinks=true,       		% false: boxed links; true: colored links
    	linkcolor=black,          	% color of internal links
    	citecolor=black,        		% color of links to bibliography
    	filecolor=black,      		% color of file links
		urlcolor=black,
		bookmarksdepth=4
}
\makeatother
% --- 

% --- 
% Espaçamentos entre linhas e parágrafos 
% --- 

% O tamanho do parágrafo é dado por:
\setlength{\parindent}{1.3cm}

% Controle do espaçamento entre um parágrafo e outro:
\setlength{\parskip}{0.2cm}  % tente também \onelineskip

% ---
% compila o indice
% ---
\makeindex
% --
% ----
% Início do documento
% ----
\begin{document}

% ----------------------------------------------------------
% ELEMENTOS PRÉ-TEXTUAIS
% ----------------------------------------------------------



 \pretextual

% ---
% Capa
% ---
\imprimircapa
% ---

% ---
% inserir o sumario
% ---
\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage
% ---


% ----------------------------------------------------------
% ELEMENTOS TEXTUAIS
% ----------------------------------------------------------
\textual

\chapter{Introdução}
	Neste capítulo serão apresentados os pontos que foram decisivos na escolha do tema do projeto, assim como as atividades a serem efetuadas para alcançar os objetivos estabelecidos.

	\section{Motivação}
	
	Atualmente, o uso de redes sociais, como Facebook, Twitter, Instagram, ocupa uma parcela significante da rotina das pessoas. Bilhões de internautas utilizam-nas diariamente não apenas para entrar em contato com seus amigos, conhecer novas pessoas e divulgar informações que julgam interessantes, mas também para expressar e compartilhar, por meio de textos, vídeos e fotos, seus pontos de vista a respeito de uma extensa gama de assuntos.
	
	Uma postagem criada por um usuário pode gerar muitas informações a respeito de seu estilo de vida: em qual cidade ele mora, onde costuma fazer compras, quais suas preferências musicais, etc. Estas informações extraídas da maneira correta transformam-se em dados sociais. A crescente disponibilidade destes dados sociais é extremamente benéfica para tarefas como branding, análise de produtos, gerenciamento de reputação corporativa e marketing de mídia social \cite{article_sentiment_analysis}. 
	
	O grande volume de dados criado pelas redes sociais torna ineficiente que pessoas obtenham, pesquisem e classifiquem dados sem ajuda computacional \cite{conference_fb}. No entanto, embora esses dados sejam facilmente compreensíveis aos seres humanos, eles não são adequados para o processamento automático: as máquinas ainda não conseguem interpretar de forma eficaz e dinâmica o significado associado ao texto em linguagem natural em ambientes muito grandes, heterogêneos, barulhentos e ambíguos como a Web \cite{article_sentiment_analysis}.

	A natureza complexa dos conteúdos compartilhados em redes sociais requer técnicas avançadas de aprendizado de máquina e processamento de linguagem natural, para que se possa extrair as opiniões dos usuários sobre um determinado tema \cite{article_sentiment_twitter}. Emular e compreender o cérebro humano é um dos principais desafios da inteligência computacional, que envolve muitos problemas-chave da Inteligência Artificial, incluindo a compreensão da linguagem humana, raciocínio e emoções. Portanto, a descoberta de informações úteis a partir desta enorme quantidade de dados não estruturados de forma automatizada continua a ser um desafio aberto \cite{article_tweet_crisis}.
	 
	
	\section{Objetivo}
	
	O objetivo deste trabalho é  compreender e aplicar técnicas de inteligência computacional e processamento linguístico para desenvolver um algoritmo capaz de entender e identificar sentimentos associados a textos de mídias sociais dentro de uma determinada temática. 
	
	 Serão pré-determinados ``grupos de sentimentos'', nos quais as postagens serão enquadradas a partir de indicadores linguísticos a serem estudados ao longo da pesquisa. A expectativa é que o sistema seja capaz de enquadrar os textos em sentimentos obtendo um resultado similar ao que um especialista conseguiria realizando o processo manualmente.
	
	Ao final do projeto, será realizada uma comparação dos resultados obtidos pelo algoritmo desenvolvido durante o trabalho com um algoritmo aleatório e com os resultados obtidos por ferramentas de computação cognitiva populares no cenário atual.	
	
	\section{Método de Trabalho}
	   
	   A pesquisa se dividirá em duas partes fundamentais: o estudo dos conceitos base que fundamentam o trabalho e o desenvolvimento de um algoritmo e de um protótipo, que colocam em prática os conhecimentos adquiridos durante este estudo. As macroatividades que a compõem estão descritas abaixo.
		
		
		\subsection*{Pesquisa Bibliográfica}
		
				\begin{itemize}
					\item Levantamento de bibliografias que abordem os temas: Computação cognitiva,  Aprendizado de Máquina, Processamento de Lingaugem Natural (PNL), Algoritmos de análise de emoções (Extreme Machine Learning - EML e Suport Vector Machine - SVM) e análises de postagens em redes sociais.
					\item Levantamento de trabalhos relacionados à temática desta pesqusa, a fim de localizar pontos que possam ser explorados ou estendidos durante a elaboração do projeto.
					
				\end{itemize}
				
		\subsection*{Estudo e Exploração Tecnológica dos Princípios de Inteligência Artifical }
				
				\begin{itemize} 
					\item Avaliação dos bancos de dados léxicos de análise de sentimentos (SentiWordNet, ConceptNet, SentiSense)
					\item Estudo da possibilidade de usar Watson (IBM) e/ou LEX (AWS) para análise dos dados
					\item Confecção do capítulo 2 do Trabalho de Conclusão de Curso (TCC), a partir dos tópicos pesquisados.
				\end{itemize}			
				
		\subsection*{Coleta dos Dados Iniciais}
		Realizar a análise de sentimentos de tweets requer uma base de dados. Para isso será realizada uma mineração de dados de posts do Twitter que constituirão o conjunto inicial para a análise.
		 
				\begin{itemize}
					\item Mineração de dados das postagens das redes sociais e armazenamento em um banco de dados para posterior análise usando WEKA \cite{article_weka} ou tweetstream \cite{tweetstream}.
				\end{itemize}
				
		\subsection*{Desenvolvimento do Algoritmo para Análise de Sentimentos}				

				\begin{itemize}
					\item Análise dos algoritmos na literatura, adaptação e desenvolvimento de um algoritmo próprio para o escopo do problema.	Consistirá na análise de eficiência dos diferentes algoritmos para textos curtos e não estruturados. E, posteriormente, adaptação para alimentar uma base de dados do Watson.

					\item Treinamento do Algoritmo: Nesta fase o sistema é treinado com o uso de um conjunto de treinamento constituído por textos previamente classificados para obter a probabilidade de que uma palavra seja positiva, negativa ou neutra dada a classe atribuída ao texto.
					\item Teste do Algoritmo: O algoritmo é testado para calcular a precisão do método.
					\item Uso do Algoritmo: Nesta fase, a entrada do algoritmo é um conjunto de textos não classificados e é determinado se são positivos, negativos ou neutros.
				\end{itemize}
				
		\subsection*{Desenvolvimento do Protótipo}
		
		Nesta atividade, o protótipo de um sistema será modelado e implementado tendo como núcleo o algoritmo de análise de sentimentos desenvolvido anteriormente. Para dar suporte a este projeto, será utilizado o método de desenvolvimento de software orientado a objetos ICONIX, que consiste nas seguintes etapas: 
		
				\begin{itemize}
					\item Análise de Requisitos
					\item Análise e Design Preliminares
					\item Design Detalhado
					\item Implementação - Escrita de códigos e testes 
					
				\end{itemize}
				
%TO DO : GIORNO ANOTOU "VER" NESSE TRECHO, NÃO SEI O QUE%				
				
		\subsection*{Avaliação dos Resultados}
		Análise estatística da acuracidade da análise de sentimentos do conjunto de posts de Twitter coletados na etapa anterior, comparando o algoritmo desenvolvido com os já descritos em literatura.
		
	\section{Organização do Texto}
		No capítulo 1, Introdução, são apresentados o tema, a motivação para a realização da pesquisa, objetivo do trabalho, contextualização dentro da área de Ciência da Computação e o método utilizado para atingir o objetivo.
		
		No capítulo 2, Revisão Bibliográfica, é apresentada a Fundamentação Teórica demandada para a realização dessa pesquisa bem como identificados e analisados Trabalhos Relacionados de apoio.
		
		No capítulo 3, Desenvolvimento do Algoritmo, o trabalho de pesquisa completo será apresentado com seus experimentos e atividades. O processo de desenvolvimento do protótipo será descrito em detalhes, com ênfase no algoritmo de classificação de emoções. 
		
		No capítulo 4, Avaliação dos Resultados, haverá uma descrição dos resultados obtidos durante o projeto e uma comparação crítica com os resultados esperados durante a idealização do trabalho e revisão bibliográfica. 

		No capítulo 5, Conclusões, haverá uma avaliação do método utilizado, assim como sugestão de linhas de pesquisa que possam complementar o trabalho no futuro.
	
\section{Cronograma}
	
	% Please add the following required packages to your document preamble:
% \usepackage[normalem]{ulem}
% \useunder{\uline}{\ul}{}
\begin{table}[!h]
\centering
\caption{Cronograma de Pesquisa}
\label{cronograma}
\begin{tabular}{l|l|l|l|l|l|l|l|l|l|l|}
\cline{2-11}
                                                                                                                                          & \multicolumn{10}{c|}{2017}                                 \\ \cline{2-11} 
                                                                                                                                          & fev & mar & abr & maio & jun & jul & ago & set & out & nov \\ \hline
\multicolumn{1}{|l|}{Pesquisa Bibliográfica}                                                                                              & x   & x   & x   & x    &     &     &     &     &     &     \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Estudo e Exploração Tecnológica dos \\ Princípios de Inteligência  Artifical \end{tabular}} &     &     & x   & x    & x   & x   &     &     &     &     \\ \hline
\multicolumn{1}{|l|}{Coleta dos Dados Iniciais}                                                                                           &     &     &     &      & x   & x   &     &     &     &     \\ \hline
\multicolumn{1}{|l|}{\begin{tabular}[c]{@{}l@{}}Desenvolvimento do Algoritmo\\  para Análise de Sentimentos\end{tabular}}                 &     &     &     &      &     & x   & x   &     &     &     \\ \hline
\multicolumn{1}{|l|}{Desenvolvimento do Protótipo}                                                                                        &     &     &     &      &     &     & x   & x   & x   &     \\ \hline
\multicolumn{1}{|l|}{Avaliação dos Resultados}                                                                                            &     &     &     &      &     &     &     &     & x   & x   \\ \hline
\end{tabular}
\end{table}	
		
\chapter{Revisão Bibliográfica}				

%TO DO: ESCREVER PREAMBULO %

\section{Fundamentação Teórica}
	
	Em relação à fundamentação teórica, é cabível abordar de maneira mais específica os conceitos de Inteligência Artifical, Computação Cognitiva, Análise de Sentimentos, Redes Sociais e o método de desenvolvimento de software orientado a objetos ICONIX.

	\subsection{Inteligência Artifical}	
	\begin{citacao} ``Atualmente, a IA abrange uma enorme variedade de subcampos, desde áreas de uso geral como aprendizado e percepção, até tarefas específicas como jogos de xadrez, demonstração de teoremas matemáticos, criação de poesia e diagnóstico de doenças. A IA sistematiza e automatiza tarefas intelectuais e, portanto, é potencialmente relevante para qualquer esfera de atividade intelectual humana. Nesse sentido, ela é verdadeiramente um campo universal.'' \cite{norvig}
	\end{citacao}

	De acordo com \citeauthor{norvig} (\citeyear{norvig}), ``Se pretendemos dizer que um dado programa pensa como um ser humano, temos de ter alguma forma de determinar como os seres humanos pensam.''
	
	Existem diversas definições respondendo ``O que é Inteligência Artificial?'', porém, cada abordagem é focada em um tipo de comportamento ou método de raciocínio que a IA pode ter. Segundo \citeauthor{norvig} (\citeyear{norvig}), estas definições podem ser divididas em 4 categorias: Pensando Humanamente, Pensando Racionalmente, Agindo Humanamente e Agindo Racionalmente. É possível ver alguns exemplos na tabela \ref{Quatro Categorias}
	

\begin{table}[!h]

\centering
{\renewcommand\arraystretch{1.25}
\begin{tabular}{|l|l|l|} \hline \toprule

\multicolumn{1}{p{7.5cm}|}{\textbf{Pensando Humanamente}} 
& 
\multicolumn{2}{p{7.5cm}|}{\textbf{Pensando Racionalmente}} \\

\multicolumn{1}{p{7.5cm}|}{
``O novo e emocionante esforço para fazer os computadores pensarem ... máquinas com mentes, no total e literal sentido.'' \cite{haugeland}

``[A automação das] atividades que associamos ao pensamento humano, atividades como a tomada de decisões, a resolução de problemas, a aprendizagem...''  \cite{bellman}

} 
& 
\multicolumn{2}{p{7.5cm}|}{

``O estudo das faculdades mentais através do uso de modelos computacionais.''  \cite{charniak_mcdermott}

``O estudo das computações que tornam possível perceber, raciocinar e agir.''  \cite{winston}

} \\

\hline


\multicolumn{1}{p{7.5cm}|}{\textbf{Agindo Humanamente}} 
& 
\multicolumn{2}{p{7.5cm}|}{\textbf{Agindo Racionalmente}} \\ 

\multicolumn{1}{p{7.5cm}|}{

``A arte de criar máquinas que executam funções que exigem inteligência quando realizadas por pessoas.''  \cite{kurzweil}

``O estudo de como fazer computadores fazer coisas em que, no momento, as pessoas são melhores.''  \cite{rich_knight}

} 
& 
\multicolumn{2}{p{7.5cm}|}{

``Inteligência computacional é o estudo do design de \textbf{agentes} inteligentes.''  \cite{poole}

``Inteligência artificial ... está preocupada com o comportamento inteligente em artefatos.''  \cite{nilsson}

} \\ \hline


\end{tabular}}
\caption{Tabela de Comportamentos}
\label{Quatro Categorias}
\end{table}
	
	As definições da esquerda medem o sucesso da IA baseando-se na fidelidade que o resultado obtido possui em relação à performace humana, sendo essa uma ciência empírica que envolve hipóteses sobre o comportamento e a cognição humana, como tomada de decisão, aprendizado e resolução de problemas. As definições da direta, por outro lado, tem como base de comparação para uma ``performance ideal'', o resultado obtido seguindo o caminho mais racional possível e agindo sempre de ``maneira correta'', tomando decisões baseadas em dados e trabalhando conhecimentos das áreas de matemática e engenharia. Cada um desses modelos de comportamentos são estudados e desenvolvidos separadamente por diversos grupos que, com a divulgação de suas pesquisas e seus resultados, cooperam a entender e melhorar o conceito que se tem de IA. \cite{norvig}
	 
	\subsubsection*{Agindo Humanamente}
		Para que seja considerada que uma maquina age como humanos, ela deve passar pelo teste de Turing, sendo esse, um teste capaz de julgar se uma máquina pode ser considerada inteligente o suficiente para possuir habilidades de conversação comparáveis as de um ser humano \cite{turing}. A maquina deve ter os seguintes recursos:
		
		\begin{itemize}
  			\item Processamento de linguagem natural - Reconhecer a linguagem e se comunicar
  			\item Representação do conhecimento - Guardar o que sabe e o que ouve
  			\item Raciocínio automatizado - Usar o que sabe para novas respostas e gerar novas conclusões
  			\item Aprendizado de Máquina - Se adaptar a novas circunstâncias
  		\end{itemize}
  			
  			Para o ``Total Turing Test'' também é necessário:
  			
  		\begin{itemize}
  			\item Visão computacional - Reconhecer objetos
  			\item Robotica - Manipular objetos e se mover
		\end{itemize}
		
	\subsubsection*{Pensando Humanamente}
		Para uma máquina pensar como humano, primeiro precisa-se entender e determinar como um pensamento humano funciona; então, a máquina deve ser modelada usando modelos cognitivos que são estudados pela Ciência Cognitiva, sendo essa a ciência que estuda como o pensamento funciona, e cria teorias testáveis através de tecnicas de psicologia \cite{wilson_keil}.
		
	\subsubsection*{Pensando Racionalmente}
		Pensar racionalmente é chegar na conclusão correta a partir de premissas. Usando o exemplo de Aristóteles: ``
Sócrates é um homem; Todos os homens são mortais; Portanto, Sócrates é mortal.''  Isto segue as ``Leis do pensamento''  \cite{laws_of_thought}.
		
	\subsubsection*{Agindo Racionalmente}
		Agir racionalmente seria uma unificação das Leis do Pensamento com o Teste de Turing, fazendo a máquina chegar no resultado esperado, e quando não for possivel chegar em um resultado, que chegue no melhor possível. No entanto, em alguns casos, não existe coisa certa a fazer, mas deve ser tomada uma decisão. Usando o exemplo de um carro autônomo, se em uma situação de emergência, ele deve escolher entre atropelar um grupo de crianças que está atravessando a rua com o farol de pedestre vermelho, ou bater no muro matando quem estiver dentro do veículo.
	
	\subsection{Aprendizado de Máquina}
		No começo das ``aplicações inteligentes'', muitos sistemas usavam regras de decisões codificadas manualmente para processar dados ou ajustar a entrada do usuário. Criar regras de decisão manualmente é viável para algumas aplicações, especialmente aquelas em que os seres humanos têm uma boa compreensão do processo de modelagem. No entanto, a lógica necessária para tomar uma decisão geralmente é específica de um único domínio e alterar a tarefa até mesmo um pouco poderia exigir uma reescrita de todo o sistema \cite {guido_muller}.

		O Aprendizado de Máquina evoluiu como um subcampo de Inteligência Artificial que envolve o desenvolvimento de algoritmos de autoaprendizagem para fazer previsões através de dados. Esse método de análise oferece uma alternativa mais eficiente para capturar o conhecimento em dados para melhorar gradualmente o desempenho de modelos preditivos \cite{ r_julian_heart}.

	\subsubsection*{Aprendizagem Supervisionada}
		É um dos mais usados e bem-sucedidos algoritmos de Aprendizado de Máquina. Para que o sistema ``aprenda'' o mapeamento a partir dos dados treinados e seja capaz de ``prever''  o valor de saída, é necessário ter um treinamento com um ``professor'' para supervisionar as saídas desejadas em cada exemplo aprendido. Exemplos de tarefas de Aprendizagem Supervisionada \cite {guido_muller}: 
	\begin{itemize}
	 	\item Identificar o código postal escrito em envelopes
		\item Determinar se um tumor é benigno com base em uma imagem médica
		\item Detectar atividade fraudulenta em transações com cartão de crédito
	\end{itemize}

	\subsubsection*{Aprendizagem não Supervisionada}
		Na Aprendizagem não Supervisionada, o sistema deve ser capaz de extrair um padrão dos dados por conta própria, sem nenhum tipo de mapeamento prévio. Apesar de ter aplicações bem sucedidas com esse método, ele é mais difícil de entender e avaliar. Exemplos de tarefas de Aprendizagem não Supervisionada \cite {guido_muller}: 
	\begin{itemize}
	 	\item Identificar e sumarizar tópicos em uma grande quantidade de dados em texto
		\item Segmentação de clientes em grupos com preferências semelhantes
		\item Detecção de padrões anormais de acesso a um site
	\end{itemize}

	\subsubsection*{Aprendizado por Reforço}
		No Aprendizado por Reforço, o objetivo é desenvolver um sistema que melhora seu desempenho com base em interações com o ambiente (feedbacks). A diferença entre ele e a aprendizagem supervisionada, é o fato de que o feedback não é o valor correto, mas uma medida de quão bem a ação foi medida por uma função de recompensa. Através da interação com o ambiente, um agente pode usar o aprendizado de reforço para aprender uma série de ações que maximizam essa recompensa por meio de uma abordagem de tentativa e erro \cite{ r_julian_heart}.

		Chess engine é um exemplo popular de reinforcement learning, pois o agente decide sobre uma série de movimentos dependendo do estado do ambiente, e a recompensa pode ser definida como ganhar ou perder no final do jogo \cite{r_julian_heart}.  %%TO DO: Aline, rever essa citaçao: Julian Heart ou EIA649B%%
	
	
	\subsection{Computação Cognitiva}

	Sendo um dos ramos da Inteligência Artificial, a Computação Cognitiva é a capacidade de máquinas pensarem como humanos. Esse termo ganhou grande repercussão quando o sistama cognitivo da IBM, Watson, conseguiu vencer o programa de TV Jeopardy em 2011.

	No entanto, um dos empecilhos para o avanço da tecnologia é a linguagem. Qualquer idioma é cheio de insinuações, idiossincrasias, expressões idiomáticas e ambiguidades; portanto, são transmitidos muitos significados nestes contextos, como 4x4 não necessariamente é 16, podendo ser também uma característica de carro.

	``IBM Watson é um sistema de PLN (Processamento de Linguagem Natural) profundo. Ele alcança a precisão tentando analisar a maior quantia de contextos possíveis. Ele obtém este contexto tanto da passagem da pergunta quanto da base de conhecimento (chamada de corpus) que está disponível para ele localizar respostas'' \cite{watson_manual}. 

	\subsection{Processamento de Linguagem Natural (PNL)}
	Em oposição às linguagens artificiais como Java, FORTRAN ou código Morse, uma linguagem natural é uma língua falada por pessoas, como Português, Inglês ou Turco. O Processamento de Linguagem Natural é uma parte importante do ramo de Inteligência Artificial, visto que a capacidade de compreender linguagens naturais está intimamente ligada ao pensamento humano. % TO DO: Aline, rever a parte da lingua falada por pessoas%
	
		\subsubsection*{PLN e Computação}
		A linguagem é uma das ferramentas centrais na vida social e profissional das pessoas. Dentre outras coisas, age como um meio de transmissão de ideias, informações, opiniões e sentimentos, assim como para persuadir, questionar e transmitir ordens \cite{book_natural_lang}.
		
	A Ciência da Computação começou a ganhar interesse por análise linguística assim que o próprio campo emergiu, principalmente no ramo da Inteligência Artificial (AI). O teste de Turing, por exemplo, um dos primeiros testes desenvolvidos para julgar se uma máquina é inteligente ou não, estipula que para ser considerada inteligente, uma máquina deve possuir habilidades de conversação comparáveis as de um ser humano \cite{turing}. Isso implica que uma máquina inteligente deve possuir habilidades de compreensão e produção, no sentido mais amplo desses termos \cite{book_natural_lang}. Ou seja, deve ser capaz de processar a linguagem de comunicação, aprender as informações contidas na mensagem, e ser capaz de transmitir o que foi aprendido. 	
	
	Em um contexto prático, o PNL é análogo ao ensino de uma língua para uma criança. Algumas das tarefas mais comuns, como a compreensão de palavras, frases e formação de sentenças gramatica e estruturalmente corretas, são muito naturais para os seres humanos, mas não triviais para computadores. No âmbito PNL, algumas dessas tarefas se traduzem em tokenização, fragmentação, parte de speech tagging, análise, tradução automática, reconhecimento de fala, análise de sentimento, e a maioria deles ainda são os desafios mais difíceis na área de computação \cite{book_natlang_python}.
		
	\subsubsection*{Definições importantes}
	O Processamento de Linguagem Natural, ou PNL, é uma disciplina que se encontra na interseção de vários ramos da ciência, como Ciência da Computação, Inteligência Artificial e Psicologia Cognitiva. 
	
Existem várias definições para a área ainda não completamente consolidadas. Mas, como descrito por  \citeauthor{book_natural_lang} (\citeyear{book_natural_lang}), por exemplo, tem-se que os termos linguística formal ou linguística computacional relacionam-se com modelos ou formalidades linguísticas desenvolvidos para implementação de TI. E os termos Tecnologia de Linguagem Humana ou Processamento de Linguagem Natural, por outro lado, referem-se a uma ferramenta de software de publicação equipada com recursos relacionados ao processamento de linguagem. 

Além disso, o processamento de fala designa uma gama de técnicas de processamento de sinais para o reconhecimento ou produção de unidades linguísticas, tais como fonemas, sílabas ou palavras. Exceto para a dimensão lidar com o processamento de sinal, não há grande diferença entre o processamento de fala e PNL. Muitas técnicas que foram inicialmente aplicadas ao processamento da fala encontraram seu caminho em aplicações em PNL; alguns exemplos são os Modelos de Markov Ocultos (HMM). Finalmente, vale a pena mencionar o termo \textit{corpus linguistics}  que se refere aos métodos de coleta, anotação e uso de corpus, tanto na pesquisa linguística quanto no PNL. Os corpus têm um papel muito importante no processo de construção de um sistema de PNL, especialmente aqueles que adotam uma abordagem de aprendizado de máquina.

	\subsubsection*{NPL e IA}
	Inteligencia Artificial (AI) tem como uma de suas descrições o estudo, design e criação de agentes inteligentes. Um agente inteligente é um sistema natural ou artificial com habilidades perceptuais que lhe permite atuar em um determinado ambiente para satisfazer seus desejos ou alcançar com êxito os objetivos \cite{norvig}. O trabalho em AI é geralmente classificado em várias subdisciplinas ou ramos, tais como representação do conhecimento, planejamento, percepção e aprendizagem. Todos esses ramos estão diretamente relacionados a PNL. Isso dá à relação entre AI e PNL uma dimensão muito importante. Muitos consideram o PNL como um ramo da AI, enquanto alguns preferem considerar o PNL uma disciplina independente. 

	
A representação do conhecimento é importante para um sistema PNL em dois níveis: Por um lado, pode fornecer um quadro para representar os conhecimentos linguísticos necessários ao bom funcionamento de todo o sistema PNL, mesmo que o tamanho e a quantidade das informações declarativas no sistema variem consideravelmente de acordo com a abordagem escolhida. Por outro lado, alguns sistemas PNL exigem informações extralinguísticas para tomar decisões, especialmente em casos ambíguos. Portanto, certos sistemas PNL são emparelhados com ontologias ou com bases de conhecimento sob a forma de uma rede semântica, um quadro ou gráficos conceituais \cite{book_natural_lang}.

Em teoria, a percepção e a linguagem parecem distantes umas das outras, mas na realidade, não é esse o caso. Fazer a conexão entre percepção e reconhecimento semântico é crucial, não só para a compreensão, mas também para melhorar a qualidade e interpretação da mensagem contida no texto. 

	\subsubsection*{PNL e Ciência Cognitiva}
	Assim como na análise linguística, a relação entre a ciência cognitiva e PNL vai em duas direções \cite{book_natural_lang}. Por um lado, os modelos cognitivos podem agir para apoiar uma fonte de inspiração para um sistema de PNL. Por outro lado, a construção de um sistema PNL de acordo com um modelo cognitivo pode ser uma forma de testar este modelo. O benefício prático de uma abordagem que imita o processo cognitivo permanece uma questão aberta porque em muitos campos, construir um sistema que é inspirado por modelos biológicos não se revela produtivo. Deve-se notar também que certas tarefas realizadas por sistemas PNL não têm paralelo em seres humanos, como a busca de informações através de mecanismos de busca ou a busca por grandes volumes de dados de texto para extrair informações úteis. A PNL pode ser vista como uma extensão das capacidades cognitivas humanas como parte de um sistema de apoio à decisão, por exemplo. Outros sistemas de PNL são muito próximos de tarefas humanas, como compreensão e produção.
	
	\subsubsection*{PNL e Data Science}	
	Com a disponibilidade de mais e mais dados digitais, surgiu recentemente uma nova disciplina: a Data Science (ciência dos dados). Trata-se de extrair, quantificar e visualizar o conhecimento, principalmente a partir de dados textuais e falados \cite{book_natural_lang}. 
	
	Grande parte da informação encontra-se não estruturada, pois foi especificamente criada para interpretação humana, sendo, dessa forma, de difícil processamento por máquinas. A PNL tem o papel de extrair e processar as informações para torná-las acessíveis e interpretáveis de forma automatizada. Atualmente, dados os inúmeros usos industriais para esse tipo de conhecimento, especialmente nos campos de marketing e tomada de decisões, esta área de estudo se tornou importante.

	\subsubsection*{Exemplo de Aplicações de PLN na atualidade}
	Atualmente são gerados petabytes de Weblogs, tweets, feeds do Facebook, bate-papos, e-mails e comentários. As empresas estão coletando todos esses tipos diferentes de dados para uma melhor segmentação de clientes e insights significativos. Para processar todas essas fontes de dados não estruturadas é necessário entender e utilizar PLN.
Seguem alguns exemplos de aplicações que utilizam NPL \cite{book_natlang_python}:

	\begin{itemize}
	 	\item Corretores de texto (MS Word/ e qualquer outro editor de texto com a funcionalidade)
	 	\item Search engines (Google, Bing, Yahoo, wolframalpha)
	 	\item Speech engines (Siri, Google Voice)
	 	\item Classificadores de Spam (Serviços de e-mail
	 	\item News feeds (Google, Yahoo!, e outros)
	 	\item Tradutores em máquina (Google Translate, e outros)
	 	\item IBM Watson
	\end{itemize}

Para alcançar algumas das aplicações acima e outros pré-processamentos básicos de PNL, existem muitas ferramentas de código aberto disponíveis. Alguns deles são desenvolvidos por organizações para construir seus próprios aplicativos de PNL, enquanto alguns deles são open-sourced. Como exemplo, seguem algumas ferramentas de PNL disponíveis \cite{book_natlang_python}:

	\begin{itemize}
	 	\item GATE
	 	\item Mallet
	 	\item Open NLP
	 	\item UIMA
	 	\item Stanford toolkit
	 	\item Genism
	 	\item Natural Language Tool Kit (NLTK)
	\end{itemize}
	
	\subsection{Análise de Sentimentos}
		A análise de sentimentos, também chamada de Opinion Mining, tem sido uma das áreas de pesquisa mais ativas no processamento de linguagem natural desde o início de 2000 \cite{bliu_2012}. O objetivo da análise de sentimento é definir ferramentas automáticas capazes de extrair informações subjetivas de textos em linguagem natural, ou seja, opiniões e sentimentos, de modo a criar conhecimento estruturado e acessível para ser usado por um sistema de apoio à decisão. É um campo emergente de análise preocupado com a aplicação de métodos computacionais para o tratamento da subjetividade no texto, com uma série de aplicações em áreas como sistemas de recomendação, publicidade contextual e business intelligence \cite{book_discover_practices}.

	\subsubsection*{Definição}
	
	A análise de sentimentos ou geração de sentimentos é uma das tarefas da PNL. Ela é definida como o processo de determinar os sentimentos por trás de uma sequência de caracteres \cite{book_natlang_python}. Trata-se de uma tarefa subjetiva, pois fornece as informações sobre o texto que está sendo expresso. Pode ser definida como um problema de classificação que pode ser de dois tipos - categorização binária (positiva ou negativa) ou categorização multi-classe (positiva, negativa ou neutra). 
	
Quando combina-se a análise de sentimentos com a mineração de tópicos, ela é referida como análise de sentimento de tópico. A análise de sentimento pode ser realizada usando um lexicon. O lexicon pode ser específico do domínio ou de natureza geral e pode conter uma lista de expressões positivas, expressões negativas, expressões neutras e palavras de parada. Quando uma sentença de teste aparece, então uma simples operação de consulta pode ser realizada através deste léxico \cite{book_natlang_python}. Um exemplo de Lexicon de analises de sentimentos é o SentiSense, que compreende 2.190 sínteses e 5.496 palavras baseadas em 14 categorias emocionais \cite{carrilho}.

Mais formalmente, como definido em \cite{bliu_2012}, uma opinião é uma quíntupla \[ \left ( e_{i}, a_{ij}, s_{ijkl},h_{k},t_{l} \right ) \]


Em que $e_{i}$ é o nome de uma entidade, $a_{ij}$ é um aspecto de $e_{i}$, $s_{ikjl}$ é o sentimento no aspecto $a_{ij}$  da entidade $e_{i}$ , $h_{k}$ denota o detentor da opinião, e $t_{l}$  é o momento em que a opinião é expressa por $h_{k}$ .

O sentimento $s_{ikjl}$ pode ser positivo, negativo ou neutro, ou expresso com diferentes níveis de intensidade, como o sistema de 1 a 5 estrelas usado pela maioria dos sites de revisão (por exemplo, em avaliações de items da Amazon).

%TO DO : Aline, aqui estava escrito "niveis de intensidade/intensidade", era pra estar assim ? % 

	\subsubsection*{Análises de Sentimentos em Mídias Sociais}
	
A grande difusão das redes sociais e seu papel na sociedade moderna estão entre as novidades mais interessantes dos últimos anos, capturando o interesse de pesquisadores, jornalistas, empresas e governos. A densa interconexão que surge frequentemente entre os usuários gera um espaço de discussão capaz de motivar e envolver os indivíduos, vinculando as pessoas com objetivos comuns e facilitando diversas formas de socialização. Isto dá origem ao chamado ``individualismo na rede'': em vez de sempre contar com uma única comunidade de referência, graças às redes sociais é possível estimular-se movendo-se entre mais pessoas e recursos, muitas vezes heterogêneos. As redes sociais estão, portanto, criando uma revolução digital. O aspecto mais interessante desta mudança não está unicamente relacionado com a possibilidade de promover a participação política e o ativismo. Esta revolução social influencia a vida de cada indivíduo. ``É a liberdade de nos expressarmos, de ter um espaço próprio onde possamos ser nós mesmos, ou de ser quem gostaríamos de ser, com poucos limites e barreiras'' \cite{book_sentiment_social}.

Neste contexto, a análise de sentimentos tenta tornar evidente o que as pessoas pensam fornecendo representações, modelos e algoritmos capazes de passar de ``texto simples não estruturado''  para ``visão complexa''. \cite{book_sentiment_social}.

	\subsubsection*{Aplicações de Opinion Mining}
	
	Opiniões dizem respeito às crenças, desejos e julgamentos expressos pelas pessoas sobre um determinado tópico e podem ser um componente importante usado para tomar decisões mais precisas em vários cenários \cite{book_discover_practices}. Empresas, por exemplo, têm um grande interesse em descobrir o que os clientes estão dizendo sobre seus produtos e ofertas de serviços. Os consumidores, por outro lado, se beneficiariam do acesso a opiniões de outras pessoas sobre os produtos que desejam comprar, uma vez que as recomendações de outros usuários tendem a influenciar essas decisões. O conhecimento das opiniões de outras pessoas também é importante em outros domínios, como o ativismo político, onde, por exemplo, pode ser interessante descobrir o sentimento geral em relação a uma nova legislação ou a partidos políticos e figuras públicas \cite{book_political_opinion}; Ou na detecção de viés subjetivo em ambientes onde não deve haver nenhum, como no monitoramento de cobertura de notícias \cite{book_Cambria2015}.

	\subsubsection*{Mídias Sociais e Análises de Tendências}
	Muitas empresas, grandes e pequenas, estão explorando se podem usar os comportamentos e comunicações on-line das pessoas para prever situações do mundo real. Por exemplo, desde 2008, o Google vem explorando se as pesquisas que chegam de usuários de todo o mundo podem permitir o rastreamento ou mesmo a previsão da ocorrência de doenças. A empresa de pesquisa demonstrou o rastreamento de duas doenças: gripe e dengue. A Figura \ref{google_flu} mostra o site Flu Trends, que foi capaz de prever a incidência de gripe com base em um conjunto de palavras-chave usadas em pesquisas durante um surto local de gripe \cite{book_social_machines}.

\begin{figure}[!h]
\centering
\includegraphics{google_flu}
\caption{Google Flu Trends}
\label{google_flu}
\end{figure}


Atualmente, o Google já não publica estimativas atuais de gripe e dengue com base em padrões de busca, mas continua a oferecer estimativas históricas produzidas pelo Google Flu Trends e Google Dengue Trends. Isto, principalmente devido à falta de acuracidade dos modelos de predição, evidenciados quando o algoritmo subestimou a necessidade de vacinas nos anos de 2011-2013 nos Estados Unidos  \cite{article_google_flu}.

Outras empresas também estão usando feeds de mídia social, como Facebook, Twitter e seus equivalentes, para entender as tendências em tudo, desde previsões de tendências de consumo quanto em monitoramento de tragédias. A tecnologia AI está sendo usada de muitas maneiras por essas empresas para extrair e entender os dados. Por exemplo, algumas empresas usam técnicas de PNL para interpretar o conteúdo de mídia social, enquanto outras empresas estão explorando como a análise de sentimento das mídias sociais pode ser usada para entender o que as pessoas estão postando. Os resultados atuais indicam que o uso de PNL juntamente com análise de sentimento ajuda a diferenciar entre ``eu me sinto bem'' e ``eu me sinto mal'', que se torna um grande diferencial no rastreamento de tendências de saúde \cite{book_social_machines}.
	
	\subsubsection*{Desafios}
Infelizmente, analisar os feeds de mídia social é muito mais difícil do que parece. Suponha que alguém escreveu um tweet ``Meu médico me disse para tomar aspirina. Como eu me sinto melhor \#not''. Embora o hashtag \#not deixa claro que ``me sinto melhor'' é sarcástico, se removemos o hashtag, não sabe-se se o escritor está sendo sério ou sarcástico.

Os sistemas atuais resolvem este problema através do acoplamento de técnicas de Aprendizado de Máquina com técnicas de análise de linguagem. No entanto, a fim de serem eficientes, estas técnicas exigem um grande número de exemplos para ser ``marcado'' por pessoas, o que significa que as pessoas explicitamente precisam indicar recursos como sentimento e sarcasmo. Uma vez que o computador tem essas informações adicionais anotadas, resultados de pesquisas atuais indicam que o computador pode, então, mais precisamente correlacionar grandes conjuntos de dados para descobrir quais palavras prever, quais recursos %TO DO: Aline, quais recursos o que ?% e usar os resultados para analisar novos conjuntos de dados \cite{book_social_machines}.

Embora a pesquisa em PNL tenha feito grandes progressos na produção de comportamentos artificialmente inteligentes, por exemplo, Google, IBM Watson e Apple Siri, nenhuma dessas estruturas PNL por si só realmente entendem o que eles estão fazendo - tornando-os não muito diferentes de um papagaio que aprende a repetir palavras sem nenhuma compreensão clara do que está dizendo. Hoje, mesmo as tecnologias de PLN mais populares visualizam a análise de texto como uma tarefa de correspondência de palavras ou padrões. Tentar verificar o significado de um pedaço de texto, processando-o no nível de palavra, no entanto, não é diferente de tentar entender uma imagem, analisando-a em nível de pixel \cite{book_Cambria2015}. 

Basear-se em palavras-chave arbitrárias, pontuação e frequências de co-ocorrência de palavras funciona bem para textos estruturados, mas uma grande quantidade de conteúdo gerado pelo usuário e o surgimento de fenômenos enganosos, como spam na web e de opinião, fazem com que os algoritmos de PNL padrão sejam cada vez menos eficientes. Para extrair e manipular adequadamente significados de texto, um sistema PNL deve ter acesso a uma quantidade significativa de conhecimento sobre o mundo e o domínio do discurso.
Para este fim, os sistemas de PNL irão gradualmente parar de confiar muito em técnicas baseadas em palavras enquanto começam a explorar a semântica de forma mais consistente e, portanto, dão um salto da Curva de sintaxe para a curva de semântica (Figura \ref{NLPCurve}).

\begin{figure}[!h]
\centering
\includegraphics{NLPCurve}
\caption{Evolução prevista da pesquisa da PLN através de três eras ou curvas diferentes \cite{book_Cambria2015}}
\label{NLPCurve}
\end{figure}

\subsection{Sentic Computing}

A Sentic Computing (SC), cujo termo deriva do ``sentire'' latino (raiz das palavras como sentimento e sensibilidade) e ``sensus'' (como em senso comum),  é uma abordagem multidisciplinar para a compreensão da linguagem natural que visa preencher a distância entre o processamento estatístico de linguagem natural (PNL) e muitas outras disciplinas que são necessárias para a compreensão da linguagem humana, como linguística, raciocínio de senso comum, computação afetiva, entre outros \cite{book_Cambria2015}.

Em particular, a SC utiliza de técnicas AI e SemanticWeb, para representação e inferência do conhecimento; Matemática, para realizar tarefas como mineração de gráficos e redução de multidimensionalidade; Linguística, para análise de discurso e pragmática; Psicologia, para modelagem cognitiva e afetiva; Sociologia, para a compreensão da dinâmica das redes sociais e da influência social; Finalmente ética, para compreender questões relacionadas com a natureza da mente e a criação de máquinas emocionais \cite{inBook_Bisio2017}.

Na SC a análise da linguagem natural baseia-se em ferramentas de raciocínio de senso comum, que permitem a análise de texto, não apenas em nível de documento, página ou parágrafo, mas também em sentença, cláusula e nível de conceito. A SC é diferente dos métodos comuns para a detecção de polaridade, pois requer uma abordagem multifacetada para o problema da análise do sentimento.

Algumas das técnicas mais populares para Opinion Mining centram-se em frequências de co-ocorrência de palavras e polaridade estatística associadas a palavras. Essas abordagens podem inferir corretamente a polaridade de textos não ambíguos com estrutura de frases simples e em um domínio específico (ou seja, o qual o classificador estatístico foi treinado). Uma das principais características da linguagem natural, no entanto, é a ambiguidade. Uma palavra como ``grande'' não possui nenhuma polaridade de forma avulsa, pois pode ser negativa, por exemplo, no caso de um ``problema grande'', ou positiva, por exemplo, em ``grande jantar'', mas a maioria dos métodos estatísticos lhe atribuem uma polaridade positiva, pois o contexto em que aparece muitas vezes é positivo.

Trabalhando no nível do conceito, a SC supera isso e muitos outros problemas comuns de framework de opinion-mining que dependem fortemente das propriedades estatísticas das palavras. 

A detecção de sentimentos é, no entanto, um problema muito desafiador porque as emoções são constructos (ou seja, quantidades conceituais que não podem ser diretamente medidas) com limites distorcidos e variações substanciais da diferença na expressão e experiência individuais \cite{inBook_Bisio2016} . Para superar esse obstáculo, a SC baseia-se em uma modelo de categorização afetiva inspirada e motivada biologica e  psicologicamente que descreve toda a gama de fatores emocionais e experiências em termos de quatro dimensões independentes, mas concomitantes, cujas diferentes níveis de ativação compõem o estado emocional total da mente \cite{book_Cambria2015}. Esse modelo é representado na forma de uma ampulheta, conforme demonstrado na figura \ref{SenticHourGlass}.


\begin{figure}[!h]
\centering
\includegraphics[scale=1.4]{SenticHourGlass}
\caption {O modelo 3D e a rede do ``Hourglass of Emotions''. Uma vez que os estados afetivos vão de fortemente positivo para nulo para fortemente negativo, o modelo assume uma forma de ampulheta \cite{book_Cambria2015}}.
\label{SenticHourGlass}
\end{figure}

	\subsection{Twitter}
	
	Twitter é uma rede social onde milhões de curtas mensagens de 140 caracteres são postadas diariamente (microblogging). Esta rede tem um crescente volume de dados graças um grande número de usuários ativos \cite{conference_twitter_alg}.

	Por ser uma ferramenta de fácil e rápida utilização, usuários utilizam a rede para comentar situações cotidianas e/ou eventos em tempo real (shows, esportes, premiações), criando o efeito de segunda tela (Tela 1: Evento ou TV, Tela 2: Smartphone conectado em redes sociais focados no assunto em si), o que tornou a rede rica em informações abrangendo diversas áreas e diversos públicos \cite{conference_twitter_sports}.

	A extração de dados dos diversos ``tweets'' se mostrou extremamente útil ultimamente, possibilitando saber qual é a popularidade de tópicos, e qual foi a reação dos usuários neste tópico,  ainda com a possibilidade de mapear qual é o público alvo (idade, sexo, localização, etc) pelo cadastro que é efetuado no ato de criação de um perfil na rede.

	Segundo o Twitter, em junho de 2016, ele contava com 313 Milhões de usuários \cite{twitter_company} postando em média 500 milhões de tweets por dia \cite{TwitterU87:online}.
	
	\subsection{ICONIX}	
	
	O ICONIX é um método de desenvolvimento de software minimalista, focado em atuar na área entre a elaboração dos casos de uso e o do código \cite{iconix}. A ênfase do método está em desenvolver uma boa análise e um bom design a partir de um processo incremental, no qual os diagramas de caso de uso são a base para cada iteração. As fases do desenvolvimento delimitadas pelo ICONIX são: Requisitos, Análise e Design Preliminares, Design Detalhado e Implementação.
	
	Na fase de Requisitos, os requisitos funcionais (que definem quais as capacidades do sistema) pré-elaborados são analisados com o intuito de realizar um modelo de domínio, um dicionário dos termos e objetos reais do seu projeto e de como eles se relacionam superficialmente. A partir do modelo de domínio, estabelecem-se os requisitos comportamentais, que detalham as ações do usuário e como o sistema deve responder a elas \cite{iconix}. Storyboads das interfaces gráficas com o usuário são uma ferramenta importante na idenficação destes requisitos, enquanto diagramas de caso de uso são utilizados para documentar cada cenário encontrado.
	
	Baseadas nos casos de uso encontrados, as demais fases se repetem a cada iteração, trabalhando alguns poucos casos de uso por vez. Durante a Análise e Design Preliminares, os casos de uso são refinados através de diagramas de robustez, ajudando a complementar o modelo de domínio com a identifição de classes antes ignoradas e dos atributos de cada classe. No Design Detalhado, cada caso de uso gera um diagrama de sequência de mensagens que descreve todas as chamadas de método que ocorrem entre os objetos naquele cenário. Com base nestes diagramas, o modelo de domínio é atualizado com os métodos descritos e torna-se um diagrama de classes.
	
	Quando a fase de Design Detalhado acaba, a modelagem realizada até o momento deve ser capaz de descrever com clareza o código a ser escrito. Inicia-se então a fase de Implementação. As classes descritas no diagrama de classes são geradas, seus métodos são implementados e testes unitários são escritos garantir o funcionamento do sistema. Essencialmente, deve-se testar todas as funções identificadas durante a análise de robustez \cite{iconix}. Também são realizados testes de integração e aceitação. Por último, revisa-se o código e atualiza-se o modelo para se preparar para a próxima iteração.  
	
	Entre cada uma das fases, atinge-se uma milestone que consiste numa revisão crítica do que foi elaborado até o momento para assegurar que os requisitos estão sendo atendidos corretamente. A elaboração dos casos de uso, diagramas de robustez e de sequência de mensagem são a parte chamada de dinâmica no ICONIX e os diagramas de domínio e de classes são a parte estática. A figura \ref{iconix_diagram} apresenta uma visão geral do processo.
	
\begin{figure}[!htb]
\centering
\includegraphics[scale=0.5]{iconix}
\caption{Visão Geral do Processo ICONIX \cite{iconix}}
\label{iconix_diagram}
\end{figure}

\section{Trabalhos relacionados}

	Um dos métodos convencionais de predição, é a utilização da frequência de repetição de palavras chave, para identificar uma tendência. Conforme descrito no trabalho de \citeauthor{article_Tsugawa2013} (\citeyear{article_Tsugawa2013}), foi investigada a eficácia dos registros das atividades no Twitter, correlacionando a frequência do uso de certas palavras para detectar a tendência depressiva dos usuários. Para tal, foi realizado um levantamento utilizando 50 homens e mulheres japoneses com aproximadamente 20 anos de idade usando o teste de Zung - Zung’s Self-rating Depression Scale (SDS). Este teste é um método popular de análise de tendência depressiva, baseado em um questionário de 20 perguntas, respondidas pelo próprio usuário, em que cada questão é pontuada de 1 a 4, e o somatório constitui a pontuação de Zung. Quanto maior a pontuação, maior sua tendência à depressão. 
	
	Neste estudo, foram realizadas análises de regressão múltipla para estimar as pontuações de Zung dos participantes a partir de freqüências de palavras usadas em suas mensagens de tweet. Os resultados experimentais mostraram que existe uma correlação positiva média (coeficiente de correlação r aproximadamente 0,45) entre pontuação de Zung calculada pelo questionário e a pontuação estimada obtida a partir do modelo de regressão. Um dos resultados interessantes deste trabalho, foi identificar que, o uso da análise de frequência de palavras como variáveis independentes não é adequado, pois quando analisadas em conjuntos de até 5 palavras chave, foi encontrado maior coeficiente de correlação.

	No entanto, basear-se em palavras-chave arbitrárias, frequências de pontuação e ocorrência de palavras pode não ser tão eficiente levando em consideração a explosão de conteúdo da Web e o surto de fenômenos enganosos como o Web trolling e o spam, que diminuem a eficiência desses métodos. Para efetivamente extrair e manipular dinamicamente significados de textos não estruturados, um sistema de PNL verdadeiramente inteligente deve considerar dados ambíguos e ter acesso a uma quantidade significativa de conhecimento sobre os possíveis ruídos dos dados e o domínio do discurso variando no tempo.

	No trabalho de \citeauthor{article_sentiment_analysis} (\citeyear{article_sentiment_analysis}) é descrito um novo paradigma que explora as relações entre os conceitos e padrões linguísticos em um texto para revelar o fluxo de sentimento de conceito a conceito. A principal novidade do artigo consiste em um algoritmo que atribui polaridade contextual a conceitos nos textos e flui essa polaridade através de arcos de dependência para atribuir um rótulo de polaridade final a cada sentença. Este algoritmo extrai o sentimento de cada palavra diretamente de recursos lexicais já existentes como SenticNet  \cite{Cambria2014}. Em seguida, aplica deslocadores de valor e combina o sentimento de palavras individuais da frase de forma semelhante aos circuitos eletrônicos, onde o sinal das fontes pode sofrer amplificação, inversão e enfraquecimento, combinando-os até obter o resultado final do balanço desses valores. Além disso, o método proposto envolve uma técnica de back-up machine-learning, que funciona nos casos em que não é encontrada informação suficiente nos recursos lexical existentes.

 	O algoritmo descrito por \citeauthor{article_sentiment_analysis} (\citeyear{article_sentiment_analysis}) utiliza o conceito de sentic pattern ou padrão de sentimento, o qual foi definido no trabalho do mesmo grupo de pesquisa \cite{article_Poria2014} e pode ser ilustrado na figura abaixo.


\begin{figure}[!htb]
\centering
\includegraphics{senticPatternsCircuit}
\caption{A ideia principal por trás do sentic patterns: a estrutura de uma sentença é como um circuito eletrônico onde os operadores lógicos canalizam os fluxos de dados de sentimento para obter a polaridade total da sentença \cite{article_sentiment_analysis}}.
\label{senticPatternsCircuit}
\end{figure}

O procedimento pode ser compreendido como um algoritmo de coloração de árvores que opera nos nós e arcos da árvore de dependência sintática. O algoritmo determina diretamente a polaridade para as palavras ou relações - conceitos, ou expressões multi-palavras – pertencentes nos recursos lexicais existentes. Em seguida, ele gradualmente estende os rótulos para outros arcos e nós, com as transformações necessárias determinadas por regras de sentic patterns, até obter o rótulo final para o elemento raiz, que é a saída desejada. O grupo denominou a extensão da polaridade como o fluxo do sentimento.

Para complementar a análise quando os dados não estavam mapeados nos Lexicons utilizados, \citeauthor{article_sentiment_analysis} (\citeyear{article_sentiment_analysis}) utilizaram uma nova técnica de inteligência computacional chamada máquina de aprendizagem extrema (Extreme Learning Machine - ELM), que é um tipo de redes feedforward de camada oculta desenvolvida recentemente, com uma camada oculta que não requer ajuste. O ELM superou os métodos de última geração, como o SVM (Support Vector Machines), tanto em termos de precisão como em tempo de treinamento. Nas experiências, Poria et al. (2015) obtiveram uma precisão global de 71,32\% no conjunto de dados final usando ELM e precisão de 68,35\% usando SVM. Esses dados foram obtidos a partir de análises em três tipos de conjuntos de dados diferentes.


O artigo escrito por \citeauthor{article_tweet_crisis} (\citeyear{article_tweet_crisis}), descreve a criação de algoritmos para reconhecimento de emoções em tweets relacionados a situações de crise, com ênfase na passagem do furacão Sandy pela costa leste dos Estados Unidos. O desafio do trabalho consistia na classificação multinomial das emoções, ao invés da classficação binárica clássica de polaridades positiva e negativa \cite{article_sentiment_twitter}. De forma similar a esta pesquisa, um outro desafio encontrado foi a linguagem utilizada nas postagens do Twitter: textos curtos e desestruturados, repletos de gírias e sarcasmo.

Os tweets foram coletados através de uma biblioteca Python e avaliados manualmente para serem enquadrados em quatro classes de emoções: raiva, medo, felicidade e outros. O objetivo dos algoritmos era enquadrar novos tweets nestas mesmas classes de acordo com a principal emoção encontrada no texto. 90\% das mensagens foram utilizadas para treino dos algoritmos e 10\% para testes. Duas soluções foram criadas com base em algoritmos de  Aprendizado de Máquina diferentes: o Naive Bayes (NB) e a Máquina de Vetores de Suporte (SVM); e diversos parâmetros variaram durante a realização dos experimentos: tamanho do n-grama, redução ou não de palavras devivadas ao seu radical (pescaria => pesca), impacto das palavras de negação, etc. 

Os resultados obtidos foram comparados com dois algoritmos de base: um que escolhia classes de forma randômica e outro baseado em regras de palavras-chave. Nestes cenários, ambas as soluções desenvolvidas, NB e SVM, obtiveram uma eficácia superior aos algoritmos de base, com 56.5\% e 59.7\% de acerto respectivamente. A precisão das respostas aumentou quando a classe de 'outros' foi removida do contexto, chegando à uma performance de 75.3\% de acerto do algoritmo de SVM. 

	%% Quero falar sobre TDD %%
	
	\chapter{Desenvolvimento do Algoritmo}
	\chapter{Avaliação dos Resultados}
	\chapter{Conclusões}
	 
	
% ----------------------------------------------------------
% Finaliza a parte no bookmark do PDF
% para que se inicie o bookmark na raiz
% e adiciona espaço de parte no Sumário
% ----------------------------------------------------------
\phantompart

% ----------------------------------------------------------Theory and Practice
% ELEMENTOS PÓS-TEXTUAIS
% ----------------------------------------------------------
\postextual
% ----------------------------------------------------------

% ----------------------------------------------------------
% Referências bibliográficas
% ----------------------------------------------------------

\bibliography{tcc_pesquisa}
	

\end{document}


% TO DO: 
% -- Referências na mesma fonte que os títulos
% -- Desenvolvimento do protótipo => VER
% -- Citação só de autor em letra maíuscula
% -- Como fazer citações de URL direito 
% -- Ficar atento aos espações após as aspas
% -- Trabalhos Relacionados => Qual a relação deles com a pesquisa ? Como contribuem para a nossa pesquisa ?
% -- Fundamentação Teórica de Machine Learning => Algoritmos de SVM, Extreme Learning e Naive Bayes
% -- Eric e Gabriel : rever a versão do livro do Norvig
%